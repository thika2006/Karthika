# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-L2A3DYnKU3ZeY4FyRZrxFS7DSdma2xg
"""



""" Upload the Dataset"""

from google.colab import files
uploaded = files.upload()

"""Load the Dataset

Data Exploration
"""

import pandas as pd
import os

# Get the current working directory
cwd = os.getcwd()
print("Current working directory:", cwd)

# List files in the current directory
print("Files in the current directory:", os.listdir(cwd))

# Assuming 'creditcard (1).csv' was uploaded using files.upload()
import pandas as pd
import os

# Get the current working directory
cwd = os.getcwd()
print("Current working directory:", cwd)

# List files in the current directory
print("Files in the current directory:", os.listdir(cwd))

# Assuming 'creditcard (1).csv' was uploaded using files.upload()
# It should be in the current working directory
try:
    df
except NameError:
    print("df is not defined")

# Check the shape of the dataset
print("Shape of the dataset:", df.shape)

# Get the column names and basic statistics
print("\nColumns:", df.columns)
print("\nBasic Statistics:\n", df.describe())

# Check data types
print("\nData Types:", df.dtypes)

"""Check for Missing Values and Duplicates

Visualize a Few Features
"""

import pandas as pd
import os

# Get the current working directory
cwd = os.getcwd()
print("Current working directory:", cwd)

# List files in the current directory
print("Files in the current directory:", os.listdir(cwd))

# Assuming 'creditcard (1).csv' was uploaded using files.upload()
# It should be in the current working directory
try:
    df
except NameError:
    print("df is not defined")
    # If df is not defined, try loading the CSV file
    try:
        # Access the uploaded file content from 'uploaded' dictionary
        df = pd.read_csv(next(iter(uploaded)))
        print("DataFrame 'df' loaded successfully.")
    except FileNotFoundError:
        print("File 'creditcard (1).csv' not found in the current directory.")
        print("Please make sure the file is uploaded and in the correct location.")
    except StopIteration:
        print("No files were uploaded.")

# Check for missing values
print("\nMissing Values:\n", df.isnull().sum())

# Check for duplicates
print("\nDuplicate Rows:", df.duplicated().sum())

import matplotlib.pyplot as plt
import seaborn as sns

# Example: Visualize distribution of a feature (e.g., 'Amount')
sns.histplot(df['Amount'], kde=True)
plt.title('Amount Distribution')
plt.show()

"""Identify Target and Features"""

# Assuming 'Class' is the target variable
X = df.drop('Class', axis=1)  # Features
y = df['Class']  # Target variable

""" Convert Categorical Columns to Numerical"""

# If there were categorical columns, you could use LabelEncoder or similar techniques
from sklearn.preprocessing import LabelEncoder

# Example:
# le = LabelEncoder()
# df['Category'] = le.fit_transform(df['Category'])

"""One-Hot Encoding"""

# One-Hot Encoding
df_encoded = pd.get_dummies(df, drop_first=True)

""" Feature Scaling"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

""" Train-Test Split"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

"""Model Building"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd # import pandas
import os

# Assuming 'creditcard (1).csv' was uploaded using files.upload()
# ... (Code to load 'df' from CSV)

# Get the current working directory
cwd = os.getcwd()
print("Current working directory:", cwd)
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd # import pandas
import os

# Assuming 'creditcard (1).csv' was uploaded using files.upload()
# ... (Code to load 'df' from CSV)

# Get the current working directory
cwd = os.getcwd()
print("Current working directory:", cwd)

# List files in the current directory
print("")
print(os.listdir())

"""Evaluation"""

from sklearn.ensemble import RandomForestClassifier # Changed to import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd # import pandas
import os

# Assuming 'creditcard (1).csv' was uploaded using files.upload()
# ... (Code to load 'df' from CSV)

# Get the current working directory
cwd = os.getcwd()
print("Current working directory:", cwd)

"""Make Predictions from New Input"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from google.colab import files # Import files

# ... (Previous code to load 'df') ...

# Assuming 'creditcard (1).csv' was uploaded using files.upload()
# Load the DataFrame (replace 'creditcard (1).csv' with the actual filename if different)
try:
    # Try to load the file using files.upload() first
    #uploaded = files.upload()  # Upload the file - This line is commented out to prevent blocking execution
    #df = pd.read_csv(next(iter(uploaded)))  # Read the uploaded file
    # If no files were uploaded, then try loading from the filename
    df = pd.read_csv('creditcard (1).csv') # Specify the correct file path
except FileNotFoundError:
    print("File 'creditcard (1).csv' not found. Please make sure it's in the correct directory or upload it.")
    # If the file is not found, exit or handle the error appropriately
    # For example:
    # raise FileNotFoundError("File 'creditcard (1).csv' not found.")
    # or
    # import sys
    # sys.exit("File not found. Exiting.")

# Assuming 'Class'

""" Convert to DataFrame and Encode"""

def preprocess_input(data_dict):
    input_df = pd.DataFrame([data_dict])
    input_df[cat_cols] = input_df[cat_cols].apply(lambda col: pd.factorize(col)[0])
    input_df = pd.get_dummies(input_df)
    input_df = input_df.reindex(columns=X.columns, fill_value=0)
    input_scaled = scaler.transform(input_df)
    return input_scaled

"""Predict the Final Grade"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# ... (Previous code to load 'df' from 'creditcard (1).csv') ...

# Check if 'Class' column exists in the DataFrame
if 'Class' not in df.columns:
    print("Error: 'Class' column not found in the DataFrame.")
    # Handle the error, e.g., exit or raise an exception
    # You might need to inspect the CSV file and find the correct column name
    # For example, if the target column is named 'Fraud', replace 'Class' with 'Fraud'
    # in the following lines
else:
    # Assuming 'Class' is the target variable and 'df' is loaded correctly
    X = df.drop('Class', axis=1)  # Features
    y = df['Class']  # Target variable

    # Now you can proceed with scaling
    scaler = StandardScaler()
    scaler.fit(X)  # Fit the scaler to your training data features (X)

# ... (rest of your code) ...

"""Deployment - Building an Interactive App"""

!pip install gradio

"""Create a Prediction Function"""

def predict_fraud(*input_data):
    import numpy as np
    input_array = np.array(input_data).reshape(1, -1)
    input_scaled = scaler.transform(input_array)
    prediction = model.predict(input_scaled)
    return "Fraudulent Transaction ðŸš¨" if prediction[0] == 1 else "Legitimate Transaction âœ…"

""" Create the Gradio Interface

"""

import gradio as gr

# Adjust the number and names of inputs as needed
feature_inputs = [gr.Number(label=col) for col in X.columns]

interface = gr.Interface(fn=predict_fraud,
                         inputs=feature_inputs,
                         outputs="text",
                         title="ðŸ”’ Credit Card Fraud Detection",
                         description="Enter transaction details to predict fraud risk.")

""" Credit Card Fraud Predictor App with Gradio

"""

import gradio as gr
import numpy as np

# ðŸŽ¯ Define the prediction function
def predict_fraud(*input_data):
    input_array = np.array(input_data).reshape(1, -1)
    input_scaled = scaler.transform(input_array)
    prediction = model.predict(input_scaled)
    return "ðŸš¨ Fraudulent Transaction" if prediction[0] == 1 else "âœ… Legitimate Transaction"

# ðŸ“Š Create Gradio interface inputs dynamically based on feature columns
feature_inputs = [gr.Number(label=col) for col in X.columns]

# ðŸŽ¨ Create Gradio interface
interface = gr.Interface(
    fn=predict_fraud,
    inputs=feature_inputs,
    outputs="text",
    title="ðŸ”’ Credit Card Fraud Detection App",
    description="Enter transaction details below to check if it's likely to be fraudulent."
)

# ðŸš€ Launch the app
interface.launch()